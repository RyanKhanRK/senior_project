# .env.example
# Backend
MLFLOW_TRACKING_URI=http://localhost:5000
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=10485760

# Frontend
VITE_API_URL=http://localhost:8000
VITE_API_WS_URL=ws://localhost:8000

---

# QUICK START GUIDE

## Prerequisites
- Docker & Docker Compose
- OR Python 3.10+, Node.js 18+, MLflow

## Option 1: Using Docker (Recommended)

### Step 1: Clone repository
git clone <your-repo-url>
cd mlflow-feature-analysis

### Step 2: Start all services
docker-compose up

Wait for all services to start. You should see:
- MLflow UI: http://localhost:5000
- Backend API: http://localhost:8000
- Frontend: http://localhost:3000

### Step 3: Train models
In another terminal:
cd backend
python train_titanic.py

### Step 4: Open dashboard
http://localhost:3000

---

## Option 2: Local Setup (Without Docker)

### Terminal 1 - MLflow Server
mlflow server --host 0.0.0.0 --port 5000

### Terminal 2 - Backend
cd backend
pip install -r requirements.txt
python main.py

### Terminal 3 - Frontend
cd frontend
npm install
npm run dev

### Terminal 4 - Train models
cd backend
python train_titanic.py

---

## Troubleshooting

### Issue: "MLflow not reachable"
Solution:
- Check if MLflow is running: curl http://localhost:5000/health
- Restart: docker-compose restart mlflow

### Issue: "Port 3000 already in use"
Solution:
- Kill existing process: lsof -i :3000 | grep LISTEN | awk '{print $2}' | xargs kill -9
- Or change port in docker-compose.yml

### Issue: "No runs appearing"
Solution:
- Run training script: python backend/train_titanic.py
- Check MLflow UI: http://localhost:5000

### Issue: "WebSocket connection refused"
Solution:
- Make sure backend is running on port 8000
- Check frontend .env has correct VITE_API_WS_URL
- Check browser console for error details